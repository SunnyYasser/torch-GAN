{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import datasets,transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_data():\n",
    "    compose = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n",
    "    out_dir = './dataset'\n",
    "    \n",
    "    return datasets.MNIST(root = out_dir,train = True,transform=compose,download = True)\n",
    "\n",
    "\n",
    "data = mnist_data()\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(data,batch_size =100,shuffle=True)\n",
    "num_batches = len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        n_features = 784\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(nn.Linear(n_features,1024),\n",
    "                                    nn.LeakyReLU(0.2),\n",
    "                                    nn.Dropout(0.3))\n",
    "        self.hidden1 = nn.Sequential(nn.Linear(1024,512),\n",
    "                                    nn.LeakyReLU(0.2),\n",
    "                                    nn.Dropout(0.2))\n",
    "        \n",
    "        self.hidden2 = nn.Sequential(nn.Linear(512,256),\n",
    "                                    nn.LeakyReLU(0.2),\n",
    "                                    nn.Dropout(0.2))\n",
    "        self.out = nn.Sequential(nn.Linear(256,n_out),\n",
    "                                    nn.Sigmoid())\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (hidden0): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.3)\n",
      "  )\n",
      "  (hidden1): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (hidden2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.2)\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_vector(images):\n",
    "    return images.view(images.shape[0],784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_images(vector):\n",
    "    return vector.view(vector.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 784\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(nn.Linear(n_features,256),\n",
    "                                    nn.LeakyReLU(0.2))\n",
    "        self.hidden1 = nn.Sequential(nn.Linear(256,512),\n",
    "                                    nn.LeakyReLU(0.2))\n",
    "        self.hidden2 = nn.Sequential(nn.Linear(512,1024),\n",
    "                                    nn.LeakyReLU(0.2))\n",
    "        self.out = nn.Sequential(nn.Linear(1024,n_out),\n",
    "                                nn.Tanh())\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x =self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (hidden0): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (hidden1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (hidden2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = Variable(torch.randn(size,100))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "x = noise(10)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2050e+00,  1.5677e-01, -1.9934e-01,  9.8299e-01, -6.0401e-01,\n",
       "         -2.6841e+00, -6.2995e-01, -1.5590e+00,  9.8946e-01,  1.9900e+00,\n",
       "         -4.9580e-01,  1.3135e+00, -4.3641e-01, -3.9364e-02,  9.6730e-01,\n",
       "          1.2551e+00,  7.9360e-01, -1.6929e+00, -7.8316e-01,  6.5946e-01,\n",
       "         -7.7041e-01,  3.9155e-01,  1.9606e-01,  2.9355e-01, -6.7046e-01,\n",
       "         -1.9068e-01,  1.0934e+00,  9.7931e-01, -7.2651e-01, -1.4129e+00,\n",
       "         -6.1852e-01, -1.8512e+00, -1.8685e+00, -7.4001e-01,  1.4150e+00,\n",
       "         -5.7120e-01, -1.6259e+00, -3.1629e-01,  1.7295e+00, -1.8937e+00,\n",
       "          1.2015e+00, -1.8396e+00,  2.8268e-01, -2.9296e-01, -2.2385e-01,\n",
       "         -1.6030e-02, -9.6601e-01,  6.5134e-01, -4.1908e-01, -5.7547e-01,\n",
       "         -9.5684e-02,  3.8932e-01, -1.2595e+00, -1.4368e+00, -3.6383e-01,\n",
       "         -8.7506e-01, -1.3983e+00, -8.6403e-01,  4.8898e-01, -1.1303e+00,\n",
       "          8.1996e-01, -7.8545e-01,  8.9278e-01, -1.0144e+00, -9.3250e-01,\n",
       "          2.8742e-01,  1.1580e+00,  1.1656e+00,  6.6826e-02,  1.3057e+00,\n",
       "         -4.8796e-01,  6.6619e-01,  2.5104e-01, -1.5372e+00,  9.0580e-01,\n",
       "         -5.1526e-01, -6.1101e-01, -4.7703e-01,  3.7338e-01,  9.2993e-01,\n",
       "         -2.0919e+00, -8.3808e-01, -6.2976e-01, -5.0976e-01,  5.7908e-01,\n",
       "         -1.0349e+00, -9.7531e-01, -3.8320e-01,  6.9007e-02,  3.3865e-01,\n",
       "          5.3531e-01, -4.7100e-01, -4.5258e-01,  5.6004e-01, -8.8251e-01,\n",
       "         -7.3616e-01, -5.7389e-02,  8.8569e-01,  2.6873e-01,  1.1530e+00],\n",
       "        [ 7.7425e-01, -6.3905e-01, -1.2332e+00,  7.6037e-01,  8.2949e-01,\n",
       "         -4.0666e-02,  5.8167e-02,  2.6255e-01, -1.2266e+00, -1.0198e-01,\n",
       "          3.5766e-01, -5.3136e-01, -1.3393e+00, -1.8698e-01,  5.2841e-01,\n",
       "          8.4131e-02, -7.3603e-01,  1.2692e-01,  4.5013e-01, -2.0393e+00,\n",
       "          1.2626e+00,  6.6996e-01, -4.3709e-01, -3.0095e-02, -8.9893e-02,\n",
       "          5.5775e-01, -6.9980e-01,  9.5212e-01,  9.5436e-01, -8.2893e-02,\n",
       "          1.6604e+00,  9.1321e-01,  2.0698e-01,  9.1086e-01,  1.2261e-01,\n",
       "         -8.1311e-01, -3.5340e-01,  6.7708e-01, -2.9843e-01,  2.1577e-01,\n",
       "          1.6947e+00, -3.1787e-01, -7.9875e-01, -3.8855e-01, -1.5162e+00,\n",
       "         -1.6220e-01, -4.7670e-01,  4.5175e-01, -5.4424e-01, -7.7852e-01,\n",
       "          1.6280e+00, -3.3862e-01, -4.1735e-01, -1.1805e+00,  4.2703e-01,\n",
       "         -9.9414e-01,  2.1066e-01,  8.8661e-01, -1.1018e+00, -9.9133e-01,\n",
       "          9.4200e-01,  8.4629e-02,  3.1987e-01,  1.0134e+00, -1.0680e+00,\n",
       "          1.1537e-01, -1.8667e+00, -2.0926e-01,  1.0532e+00, -1.3363e+00,\n",
       "          9.7442e-01, -4.0171e-02,  9.1997e-02,  1.7793e+00,  2.8394e-01,\n",
       "         -1.1905e+00, -7.1992e-01, -7.4170e-01, -8.4700e-01,  1.2577e+00,\n",
       "         -1.5369e+00, -1.6584e+00,  1.5838e-01,  9.3687e-01, -4.9087e-01,\n",
       "         -2.1555e+00,  2.0319e-01, -4.4910e-02,  1.3356e-02,  1.0268e+00,\n",
       "         -1.0485e+00,  1.1000e-02, -2.8262e-01,  5.4710e-01,  1.9203e+00,\n",
       "         -7.3063e-01,  3.7294e-01, -1.6560e+00,  5.6933e-01,  1.6988e-01],\n",
       "        [-1.0558e+00, -7.4141e-01,  4.2041e-01, -7.8402e-01,  1.6889e-01,\n",
       "         -1.3095e-01,  1.0307e+00, -5.0625e-01,  9.0461e-01, -1.6875e+00,\n",
       "          2.1353e+00, -1.0543e+00,  2.3113e+00,  1.8906e-01,  1.7416e+00,\n",
       "         -1.3479e+00,  7.0974e-01, -1.7741e-01, -2.1748e+00,  3.7444e-02,\n",
       "         -4.2169e-01, -5.7583e-01,  1.8509e+00, -1.3910e+00, -2.0049e+00,\n",
       "         -1.7490e+00,  4.4089e-01,  2.6708e-01, -9.2715e-01,  8.9875e-01,\n",
       "          2.4353e+00,  3.8690e-01,  1.7116e+00,  6.8336e-01,  3.1893e-01,\n",
       "          1.8436e+00,  4.5248e-01,  5.4906e-01, -7.8643e-01,  5.8801e-01,\n",
       "         -1.8087e-01, -9.4579e-01,  8.0758e-01,  3.1467e-02,  3.0143e-01,\n",
       "          7.8438e-01,  2.4741e+00,  2.3677e-01, -8.1440e-01,  3.9279e-01,\n",
       "          1.0281e+00, -5.4192e-01,  6.2236e-01,  3.0326e-01, -1.0241e+00,\n",
       "          1.0854e+00,  1.7783e+00, -3.9715e-01, -1.1959e+00,  1.3602e+00,\n",
       "          8.3145e-01, -7.1064e-01, -7.7467e-01,  4.3645e-01, -1.2148e+00,\n",
       "          5.9630e-01,  9.6526e-01, -2.3493e-02, -9.4311e-01,  4.4801e-01,\n",
       "         -8.9513e-01,  3.5325e-01,  1.1978e+00,  1.8250e+00, -1.8406e-01,\n",
       "          1.5023e+00, -2.8974e-01, -5.4008e-01, -1.5279e+00, -1.6786e+00,\n",
       "         -1.8764e-01,  3.3566e-01,  1.0377e-01, -9.0028e-01,  1.0651e-01,\n",
       "         -1.5085e+00,  1.8206e-01, -6.3976e-01, -1.0932e+00,  1.2319e+00,\n",
       "          3.7753e-01, -1.0636e+00, -1.0856e-01,  2.7811e-01,  4.4268e-01,\n",
       "         -3.0647e-01, -7.0442e-01, -1.4331e+00,  7.3562e-01,  1.0323e+00],\n",
       "        [ 1.0715e-01, -4.3894e-01,  1.7695e-01, -1.2787e+00,  9.6945e-01,\n",
       "          8.8565e-01,  2.7123e-01, -1.6038e+00,  5.9451e-01,  7.0428e-01,\n",
       "          1.3304e+00,  3.5744e-01, -2.5365e-01, -3.1881e-01, -7.6588e-01,\n",
       "         -1.2354e+00,  1.3513e-01, -2.9819e-01,  1.6595e-01,  1.6026e-01,\n",
       "         -2.4881e-01, -1.0069e+00,  1.0349e+00,  6.9448e-01, -6.6390e-01,\n",
       "         -5.3124e-01, -9.4046e-01,  8.7295e-01,  9.1578e-01,  2.6270e-01,\n",
       "          7.7346e-01, -2.6151e+00, -3.6865e-01,  1.7023e-02,  1.2936e+00,\n",
       "         -3.2247e-01,  3.3629e-01, -4.3845e-01,  2.4984e-01, -5.4779e-01,\n",
       "         -5.4862e-01, -2.2323e-01, -1.0530e+00, -6.9076e-01,  1.4673e-01,\n",
       "          1.4329e+00, -1.1605e+00,  6.3465e-01, -4.1142e-01, -3.5704e-01,\n",
       "          8.8584e-01, -1.7649e+00,  1.0039e+00,  3.8731e-01, -5.0880e-01,\n",
       "          4.6431e-01, -1.0558e-01,  2.6090e+00,  1.6948e+00, -1.1066e+00,\n",
       "          2.6704e-01,  9.1605e-01, -2.7567e-01,  5.1154e-01,  2.3720e-01,\n",
       "         -7.6828e-02, -3.4464e-01, -5.4234e-01,  3.1679e+00, -1.1425e+00,\n",
       "          1.4117e+00, -2.2934e-01,  1.0725e-01,  3.5936e-01,  2.2000e-01,\n",
       "          2.5889e+00,  2.1247e-01,  1.3946e+00, -1.5537e+00, -1.4461e+00,\n",
       "         -6.1236e-01,  1.2353e+00,  1.4022e+00,  9.0809e-01,  7.0316e-01,\n",
       "          3.8816e-01, -5.0488e-02,  4.9125e-01,  8.2315e-01,  1.3993e+00,\n",
       "         -8.7463e-01,  4.0587e-01,  8.3905e-01,  1.2924e-01, -3.8596e-01,\n",
       "         -3.7175e-02, -3.0482e-01, -1.3826e-01,  9.0497e-01,  3.2191e-01],\n",
       "        [ 2.2110e+00,  1.2928e+00,  7.1579e-01, -1.9377e-01,  2.1969e+00,\n",
       "          2.4086e+00,  4.1758e-02,  8.7093e-01,  1.1778e+00, -2.5057e-01,\n",
       "         -7.3256e-01,  1.5478e+00, -1.3063e+00, -9.4757e-01, -1.5144e+00,\n",
       "         -6.3347e-01,  1.2233e-01,  1.5282e-01,  6.6738e-01, -8.3499e-01,\n",
       "          6.7243e-01, -3.3161e-01, -1.5825e+00, -6.9621e-01,  1.4237e+00,\n",
       "         -5.1037e-01, -6.4233e-01,  8.5397e-01,  1.6473e+00,  2.0411e+00,\n",
       "          1.2220e+00,  1.0631e+00,  4.3339e-01, -9.3896e-01,  3.6179e-01,\n",
       "         -1.7262e+00,  4.4525e-01, -1.6434e-01,  1.1956e+00, -2.1492e+00,\n",
       "         -7.6570e-01,  1.1587e+00, -1.7134e+00,  6.1201e-01,  2.0144e-03,\n",
       "         -5.6188e-01,  6.7462e-02, -8.8563e-01, -8.9941e-02,  5.3131e-01,\n",
       "         -2.3090e+00,  2.8409e-01, -1.9367e-01, -8.9615e-02, -1.5676e-01,\n",
       "          1.3230e+00, -1.0007e+00, -1.5248e-01, -1.2614e+00,  8.5273e-01,\n",
       "          1.0118e+00,  1.3424e+00,  1.1925e+00,  7.6296e-01, -4.5548e-01,\n",
       "         -6.4045e-01,  3.3232e-01, -3.4201e-01, -1.8343e-01, -2.1572e+00,\n",
       "          6.7275e-02, -2.5072e-01,  6.7483e-01, -4.2966e-01,  7.8082e-01,\n",
       "         -1.5289e+00, -1.1263e-02, -5.6565e-02,  1.1588e+00,  1.2670e+00,\n",
       "          1.1219e+00, -1.3789e+00, -2.2683e-01,  2.1730e-01, -1.3313e+00,\n",
       "          3.9193e-02,  4.4101e-02,  2.2992e-03, -1.1594e+00,  2.7337e-01,\n",
       "          1.6343e+00, -2.7693e-01, -1.2387e+00, -1.8103e+00, -2.0466e+00,\n",
       "          1.0524e+00, -1.4681e+00, -1.2598e+00, -5.7737e-01, -6.9799e-03],\n",
       "        [-2.4702e-01, -1.3516e+00, -7.0948e-01, -8.4265e-01,  1.5401e+00,\n",
       "          1.3801e-01,  3.3633e-01,  1.7723e-01, -4.7481e-01, -1.0996e+00,\n",
       "         -5.1071e-03,  3.7317e-01,  7.1529e-01,  4.4174e-01, -4.5955e-01,\n",
       "         -6.9488e-01, -3.5164e-01,  5.6615e-01,  5.5613e-01, -3.3554e-01,\n",
       "         -1.2046e-01, -1.9474e+00, -2.3336e+00,  1.3341e+00,  6.7287e-02,\n",
       "          4.7982e-01,  4.0685e-01,  6.4275e-01, -6.5716e-01, -1.2134e+00,\n",
       "          1.8128e+00,  5.4020e-01,  4.0653e-01, -1.4630e+00, -2.4899e+00,\n",
       "         -9.1633e-01,  5.0509e-01, -2.0387e-01,  8.2435e-01,  4.0471e-01,\n",
       "          3.1753e-01,  2.0388e+00,  4.8193e-01, -7.0983e-01, -4.0438e-01,\n",
       "          1.8772e+00,  5.7390e-01, -5.3066e-02,  1.6271e-01, -1.1123e+00,\n",
       "         -3.8451e-01,  8.8767e-01, -1.2031e+00,  6.3691e-01, -9.5295e-01,\n",
       "          1.6782e+00, -1.0410e-01, -6.1313e-01,  1.1550e+00,  5.3426e-01,\n",
       "         -5.4448e-01, -1.9326e+00,  7.0585e-02, -8.8431e-01,  4.7713e-01,\n",
       "          1.8319e+00,  1.0118e+00,  6.9770e-01, -5.9618e-01, -9.5238e-01,\n",
       "         -1.9309e-01, -4.1049e-01,  1.7200e+00, -2.1276e-01, -1.4609e-01,\n",
       "         -1.5759e+00, -1.3814e+00,  6.4281e-01, -1.1509e-02, -3.1935e-02,\n",
       "          4.6344e-01,  6.4760e-01,  5.8159e-01,  4.8845e-01,  4.7722e-01,\n",
       "         -2.6091e-01, -5.4859e-01,  3.0405e+00,  4.0805e-02, -9.1931e-02,\n",
       "          6.4567e-01,  2.6396e-01,  7.1861e-01, -2.0641e+00,  2.4535e-01,\n",
       "         -4.3089e-01,  1.4060e-01, -3.2292e-01, -5.6258e-01,  1.8448e+00],\n",
       "        [-8.6349e-01,  3.9027e-01,  3.4953e-01, -3.0548e-01, -2.6073e-01,\n",
       "          1.0937e+00,  3.8594e-01, -1.3527e-01,  4.5133e-01, -1.3587e+00,\n",
       "          1.1500e+00,  2.4120e-01,  2.9944e-01,  7.5024e-01,  6.6862e-01,\n",
       "          1.0352e+00,  1.3253e+00, -3.8038e-01,  3.8202e-02, -6.3153e-01,\n",
       "         -1.5071e+00,  1.7401e-01, -1.1151e+00, -8.5126e-01, -6.1493e-01,\n",
       "          9.8923e-01, -1.6841e+00, -8.5951e-01,  4.2197e-01,  4.4438e-01,\n",
       "          2.7342e+00,  6.8165e-01, -2.2771e-02,  1.2018e+00, -3.3559e-01,\n",
       "         -2.7784e-01,  1.5289e+00,  5.0613e-01,  1.3319e+00, -1.0176e-01,\n",
       "          3.6325e-01, -2.7726e-02, -9.5499e-01, -8.7015e-01, -5.8952e-01,\n",
       "          1.0748e+00,  6.1304e-01, -7.5945e-01, -9.0712e-01,  7.7157e-01,\n",
       "          2.1450e-01,  6.1868e-01,  6.9654e-01,  4.5000e-01, -1.3765e-01,\n",
       "         -9.0783e-01,  6.4145e-01,  2.4774e-01,  3.0269e-01,  1.1267e+00,\n",
       "         -5.2881e-01, -5.6430e-01, -3.5168e-01,  4.8059e-01, -3.9636e-01,\n",
       "         -1.0309e+00,  5.5627e-01, -3.6624e-01,  9.8440e-01, -9.2003e-01,\n",
       "          5.0814e-01, -6.1426e-01,  4.5694e-01, -1.7417e+00,  1.0392e+00,\n",
       "         -4.6921e-01,  9.5402e-02, -4.5550e-01,  2.0143e+00,  4.8954e-01,\n",
       "         -1.7188e+00, -3.3003e-01, -8.5740e-01,  1.5989e+00, -1.0306e+00,\n",
       "          9.1429e-01, -1.1871e+00,  8.4596e-01,  3.0183e-01, -8.4723e-01,\n",
       "          1.5143e+00, -5.6441e-01, -4.0134e-01,  1.7007e+00, -2.8275e-01,\n",
       "         -8.1440e-01, -1.1323e+00, -6.4378e-01, -5.2227e-01,  6.1218e-01],\n",
       "        [ 7.9180e-01,  1.1357e+00,  1.2398e+00, -1.9858e+00,  2.0023e+00,\n",
       "          9.1915e-01,  6.8713e-01,  1.5532e+00, -4.4176e-01,  1.0742e+00,\n",
       "          9.2941e-01,  1.3709e+00,  2.0442e-03,  1.0790e+00,  5.9408e-01,\n",
       "          1.1736e+00,  3.2353e-01,  1.1410e+00, -9.7718e-01, -1.3865e+00,\n",
       "          7.0703e-01, -1.3742e-01, -1.3779e-01,  2.4327e+00, -6.7009e-01,\n",
       "         -4.8018e-01, -3.7900e-01,  5.9540e-01, -6.4953e-01,  4.3380e-01,\n",
       "          9.6237e-01,  1.0943e+00, -1.6238e+00,  2.3718e+00,  5.7444e-01,\n",
       "          4.6894e-01,  1.2291e+00, -1.5595e+00,  1.3312e+00,  1.0737e+00,\n",
       "          6.6214e-01, -1.9361e-01,  5.9317e-01,  1.0542e-01,  1.5212e-01,\n",
       "         -6.3472e-01,  1.2673e-01, -1.1756e-01, -5.9916e-01,  1.3449e+00,\n",
       "         -1.1715e+00,  1.2573e+00,  9.7310e-01, -2.0301e+00, -9.0260e-01,\n",
       "          3.8070e-01,  1.2875e+00,  8.0678e-01,  4.1860e-01, -4.2633e-02,\n",
       "          8.7930e-01,  1.9498e+00,  9.5151e-01,  3.2042e-01, -2.4040e-01,\n",
       "         -3.8872e-01,  9.8158e-01, -1.4641e+00,  1.6841e+00, -2.7606e-01,\n",
       "         -3.7624e-02, -1.3017e+00, -1.2232e+00, -9.8746e-02, -5.1153e-01,\n",
       "         -4.6006e-01, -5.7548e-01,  2.0031e-01, -1.8684e+00, -3.8161e-01,\n",
       "          8.7216e-01,  3.0784e-02,  8.8952e-01,  8.8413e-01, -1.6161e+00,\n",
       "          1.8316e-01, -1.1319e+00, -2.9191e+00,  1.1307e+00, -1.1283e+00,\n",
       "          3.1774e+00,  9.1425e-02, -2.6056e+00, -1.3649e+00,  3.8160e-01,\n",
       "          4.9676e-01,  2.4991e-01, -2.3908e-01,  3.4167e-01,  1.1181e-01],\n",
       "        [ 1.2170e+00, -1.3302e-01, -1.0504e+00, -9.9339e-01, -8.9850e-01,\n",
       "         -1.6807e-01, -4.4351e-02,  2.7314e-01,  1.4173e+00,  1.0133e+00,\n",
       "          1.5165e+00, -7.5489e-01, -1.4645e+00, -7.5461e-01, -6.0553e-01,\n",
       "          9.9778e-01,  1.1187e+00,  2.2538e-01, -5.0057e-01, -4.8281e-01,\n",
       "         -1.8144e+00,  8.7249e-02, -1.0522e+00,  1.1379e+00,  5.4944e-01,\n",
       "         -9.9002e-01,  5.7248e-01,  1.2277e+00,  8.9522e-01,  2.3445e-02,\n",
       "         -1.1183e+00,  5.9570e-01, -1.0906e+00, -1.1680e+00,  5.8960e-01,\n",
       "         -3.6476e-02, -7.8765e-02, -5.3088e-02, -4.0055e-01, -5.1137e-02,\n",
       "          1.2989e+00,  1.1908e+00, -4.7734e-01,  3.1347e-01,  1.2806e+00,\n",
       "         -3.9058e-01,  5.3350e-02, -3.1062e-02,  1.5236e+00,  1.2430e+00,\n",
       "         -6.7446e-01, -6.4281e-01, -5.5432e-01, -2.0574e-01, -2.2736e+00,\n",
       "         -3.7756e-01,  4.1398e-01, -9.6503e-01,  6.0021e-01, -1.8734e+00,\n",
       "         -2.5713e+00, -1.3683e+00, -1.4306e+00,  2.1354e-01, -5.5151e-01,\n",
       "          3.3441e-01, -4.8137e-01, -1.2659e+00, -2.1244e+00, -7.3361e-01,\n",
       "         -1.9504e-01,  5.0986e-01,  1.3123e+00,  2.4468e+00, -6.9955e-01,\n",
       "         -2.7347e-01,  8.3089e-01,  1.3560e-03, -4.1989e-02, -2.9518e-01,\n",
       "         -6.7532e-01, -4.9273e-01,  4.3521e-01,  7.1044e-01, -9.0581e-01,\n",
       "          3.8039e-01,  3.1127e-01,  1.3806e+00,  8.7095e-02,  5.1397e-01,\n",
       "          2.2204e-01,  1.0065e+00,  9.0428e-01, -2.9594e-01,  3.8971e-01,\n",
       "          1.5412e+00,  1.0930e+00, -1.6563e-03,  1.8327e+00, -9.6195e-01],\n",
       "        [ 2.7446e-01,  6.9777e-01,  8.9666e-01, -4.3384e-01,  1.5117e+00,\n",
       "          1.1111e+00, -8.3506e-01,  1.6661e+00, -7.2150e-03, -1.2825e+00,\n",
       "         -4.6668e-01,  6.2631e-01,  2.4759e-01, -3.0454e-01, -2.0493e-01,\n",
       "          4.0100e-02, -1.0110e+00, -8.5492e-01,  1.2453e+00,  2.3957e-01,\n",
       "          5.2698e-01, -1.3535e+00, -1.6886e-01, -8.6736e-01,  1.8469e+00,\n",
       "          1.3006e+00, -5.0642e-01,  9.2986e-01, -8.0065e-01, -1.2663e-01,\n",
       "          8.8336e-02, -1.2477e-02, -6.5949e-01, -1.0308e+00, -7.7890e-01,\n",
       "         -3.8192e-01, -9.5267e-02,  3.7695e-01, -5.0352e-02,  8.0836e-01,\n",
       "          3.7348e-01, -1.6435e-01,  2.9887e-01,  1.4422e+00,  1.3053e+00,\n",
       "          4.4803e-02, -4.9179e-01, -8.0685e-03, -3.5974e-01, -1.4511e+00,\n",
       "          3.5772e-01,  1.2606e+00,  3.3062e+00,  8.2474e-02,  6.7337e-01,\n",
       "          6.6087e-01, -4.8911e-01,  2.7367e-01, -5.1840e-01,  1.9767e-01,\n",
       "         -8.2078e-01, -3.8344e-01,  1.7281e+00,  1.1727e+00, -2.4365e-01,\n",
       "          1.1200e+00, -1.8561e+00, -1.3311e-01, -1.1382e+00, -9.6106e-01,\n",
       "         -5.6807e-01,  4.7096e-01,  1.3004e+00, -1.0383e+00, -4.7275e-01,\n",
       "         -1.5677e+00, -1.7348e-01,  3.8796e-01,  1.3461e-01,  1.7464e+00,\n",
       "         -2.5662e+00,  9.5979e-02, -2.7019e-01, -6.2485e-01, -3.3412e-01,\n",
       "          4.6469e-01, -2.6771e-01, -1.1263e+00, -1.4013e-03,  3.5124e-01,\n",
       "          1.2228e-01, -5.7742e-01,  1.4834e+00, -2.5267e+00,  7.1188e-01,\n",
       "         -6.6808e-02,  1.0193e-01,  5.4903e-01,  7.3781e-01, -8.3093e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optim.Adam(discriminator.parameters(),lr = 0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(),lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    data = Variable(torch.ones(size,1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros_target(size):\n",
    "    data = Variable(torch.zeros(size,1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer,real_data,fake_data):\n",
    "    N = real_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Training on real data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = loss(prediction_real,ones_target(N))\n",
    "    error_real.backward()\n",
    "    \n",
    "    # Training on fake_data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = loss(prediction_fake,zeros_target(N))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return error_real + error_fake,prediction_real,prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer,fake_data):\n",
    "    N = fake_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = discriminator(fake_data)\n",
    "    error = loss(pred,ones_target(N))\n",
    "    error.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(model_name = 'GAN',data_name = 'MNIST')\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in epochs:\n",
    "    for n_batch,(real_batch,_) in enumerate(dataloader):\n",
    "        N = real_batch.size(0)\n",
    "        real_data = Variable(images_to_vector(real_batch))\n",
    "        fake_data = generator(noise(N)).detach()\n",
    "        # to do complete training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
